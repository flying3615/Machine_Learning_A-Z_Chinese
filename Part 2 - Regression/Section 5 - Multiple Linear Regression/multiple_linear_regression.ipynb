{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "线性回归区别\n",
    "\n",
    "![简单线性回归和多元线性回归区别](./img/vs.png)\n",
    "\n",
    "分类数据用dummy variable转换\n",
    "\n",
    "![dummy variable](./img/dummy_var.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "总是要省略一列防止过度拟合 (X-1)\n",
    "![omit_one](./img/omit_one.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "反向淘汰（Backward Elimination）是一种特征选择技术，常用于多元线性回归模型中。其基本思想是：先将所有的预测变量包含在模型中，然后逐步移除最不重要的特征，直到所有剩余的特征都是重要的（即对模型的预测性能有显著贡献）。\n",
    "\n",
    "反向淘汰的具体步骤如下：\n",
    "\n",
    "**包含所有特征：**首先，我们建立一个包含所有预测变量的模型。\n",
    "\n",
    "**计算每个特征的重要性：**然后，我们计算每个特征对模型预测能力的贡献。在多元线性回归中，这通常通过计算每个特征的 P 值来实现。P 值表示了特征的系数是否显著不等于零的概率。较高的 P 值（通常大于某个阈值，如 0.05）表示特征可能不重要。\n",
    "\n",
    "**移除最不重要的特征：**我们移除 P 值最大（即最不重要）的特征。\n",
    "\n",
    "**重复步骤 2 和 3：**我们反复计算每个特征的重要性，然后移除最不重要的特征，直到所有剩余的特征都是重要的。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "前向选择（Forward Selection）是一种特征选择技术，常用于多元线性回归模型中。其基本思想是：从没有预测变量的模型开始，然后逐步添加最重要的特征，直到添加更多的特征不能显著提高模型的预测性能。\n",
    "\n",
    "前向选择的具体步骤如下：\n",
    "\n",
    "**开始没有特征的模型：**首先，我们建立一个没有预测变量的模型，只有一个截距。\n",
    "\n",
    "**计算每个特征的重要性：**然后，我们计算每个特征对模型预测能力的贡献。在多元线性回归中，这通常通过计算每个特征的 P 值来实现。P 值表示了特征的系数是否显著不等于零的概率。较低的 P 值（通常小于某个阈值，如 0.05）表示特征可能是重要的。\n",
    "\n",
    "**添加最重要的特征：**我们添加 P 值最小（即最重要）的特征。\n",
    "\n",
    "**重复步骤 2 和 3：**我们反复计算每个特征的重要性，然后添加最重要的特征，直到添加更多的特征不能显著提高模型的预测性能。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "双向淘汰（Bidirectional Elimination），也被称为逐步回归（Stepwise Regression），是一种特征选择方法，结合了前向选择和反向淘汰的策略。它在每一步都会评估添加新特征或者删除已有特征对模型性能的影响，然后选择最好的策略。\n",
    "\n",
    "双向淘汰的具体步骤如下：\n",
    "\n",
    "**开始没有特征的模型：**首先，我们建立一个没有预测变量的模型，只有一个截距。\n",
    "\n",
    "**前向选择：**然后，我们像前向选择一样，逐步添加最重要的特征，直到添加更多的特征不能显著提高模型的预测性能。\n",
    "\n",
    "**反向淘汰：**在每次添加新特征后，我们像反向淘汰一样，检查是否有已有的特征变得不重要（例如，它的 P 值变得较高）。如果有，我们就移除这个特征。\n",
    "\n",
    "**重复步骤 2 和 3：**我们反复进行前向选择和反向淘汰，直到不能添加或移除任何特征。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   R&D Spend  Administration  Marketing Spend       State     Profit\n0  165349.20       136897.80        471784.10    New York  192261.83\n1  162597.70       151377.59        443898.53  California  191792.06\n2  153441.51       101145.55        407934.54     Florida  191050.39\n3  144372.41       118671.85        383199.62    New York  182901.99\n4  142107.34        91391.77        366168.42     Florida  166187.94\n5  131876.90        99814.71        362861.36    New York  156991.12\n6  134615.46       147198.87        127716.82  California  156122.51\n7  130298.13       145530.06        323876.68     Florida  155752.60\n8  120542.52       148718.95        311613.29    New York  152211.77\n9  123334.88       108679.17        304981.62  California  149759.96",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>R&amp;D Spend</th>\n      <th>Administration</th>\n      <th>Marketing Spend</th>\n      <th>State</th>\n      <th>Profit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>165349.20</td>\n      <td>136897.80</td>\n      <td>471784.10</td>\n      <td>New York</td>\n      <td>192261.83</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>162597.70</td>\n      <td>151377.59</td>\n      <td>443898.53</td>\n      <td>California</td>\n      <td>191792.06</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>153441.51</td>\n      <td>101145.55</td>\n      <td>407934.54</td>\n      <td>Florida</td>\n      <td>191050.39</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>144372.41</td>\n      <td>118671.85</td>\n      <td>383199.62</td>\n      <td>New York</td>\n      <td>182901.99</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>142107.34</td>\n      <td>91391.77</td>\n      <td>366168.42</td>\n      <td>Florida</td>\n      <td>166187.94</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>131876.90</td>\n      <td>99814.71</td>\n      <td>362861.36</td>\n      <td>New York</td>\n      <td>156991.12</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>134615.46</td>\n      <td>147198.87</td>\n      <td>127716.82</td>\n      <td>California</td>\n      <td>156122.51</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>130298.13</td>\n      <td>145530.06</td>\n      <td>323876.68</td>\n      <td>Florida</td>\n      <td>155752.60</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>120542.52</td>\n      <td>148718.95</td>\n      <td>311613.29</td>\n      <td>New York</td>\n      <td>152211.77</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>123334.88</td>\n      <td>108679.17</td>\n      <td>304981.62</td>\n      <td>California</td>\n      <td>149759.96</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('50_Startups.csv')\n",
    "dataset.head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 选取除了最后一列的所有列，并将选取的数据转换为一个 NumPy 数组作为自变量X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 选取最后一列，并将选取的数据转换为一个 NumPy 数组作为因变量y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "y = dataset.iloc[:, 4].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "处理分类数据"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehotencoder = OneHotEncoder()\n",
    "X_reshaped = X[:, 3].reshape(-1, 1)  # 第三列地点，转换为二维数组\n",
    "X_onehot = onehotencoder.fit_transform(X_reshaped).toarray()  # 对第一列进行 one-hot 编码"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "处理虚拟变量陷阱，去除第一列"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "X_onehot = X_onehot[:, 1:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "去除掉最后一列(地址)， 将编码的结果合并在一起："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.0, 1.0, 165349.2, 136897.8, 471784.1],\n       [0.0, 0.0, 162597.7, 151377.59, 443898.53],\n       [1.0, 0.0, 153441.51, 101145.55, 407934.54],\n       [0.0, 1.0, 144372.41, 118671.85, 383199.62],\n       [1.0, 0.0, 142107.34, 91391.77, 366168.42],\n       [0.0, 1.0, 131876.9, 99814.71, 362861.36],\n       [0.0, 0.0, 134615.46, 147198.87, 127716.82],\n       [1.0, 0.0, 130298.13, 145530.06, 323876.68],\n       [0.0, 1.0, 120542.52, 148718.95, 311613.29],\n       [0.0, 0.0, 123334.88, 108679.17, 304981.62],\n       [1.0, 0.0, 101913.08, 110594.11, 229160.95],\n       [0.0, 0.0, 100671.96, 91790.61, 249744.55],\n       [1.0, 0.0, 93863.75, 127320.38, 249839.44],\n       [0.0, 0.0, 91992.39, 135495.07, 252664.93],\n       [1.0, 0.0, 119943.24, 156547.42, 256512.92],\n       [0.0, 1.0, 114523.61, 122616.84, 261776.23],\n       [0.0, 0.0, 78013.11, 121597.55, 264346.06],\n       [0.0, 1.0, 94657.16, 145077.58, 282574.31],\n       [1.0, 0.0, 91749.16, 114175.79, 294919.57],\n       [0.0, 1.0, 86419.7, 153514.11, 0.0],\n       [0.0, 0.0, 76253.86, 113867.3, 298664.47],\n       [0.0, 1.0, 78389.47, 153773.43, 299737.29],\n       [1.0, 0.0, 73994.56, 122782.75, 303319.26],\n       [1.0, 0.0, 67532.53, 105751.03, 304768.73],\n       [0.0, 1.0, 77044.01, 99281.34, 140574.81],\n       [0.0, 0.0, 64664.71, 139553.16, 137962.62],\n       [1.0, 0.0, 75328.87, 144135.98, 134050.07],\n       [0.0, 1.0, 72107.6, 127864.55, 353183.81],\n       [1.0, 0.0, 66051.52, 182645.56, 118148.2],\n       [0.0, 1.0, 65605.48, 153032.06, 107138.38],\n       [1.0, 0.0, 61994.48, 115641.28, 91131.24],\n       [0.0, 1.0, 61136.38, 152701.92, 88218.23],\n       [0.0, 0.0, 63408.86, 129219.61, 46085.25],\n       [1.0, 0.0, 55493.95, 103057.49, 214634.81],\n       [0.0, 0.0, 46426.07, 157693.92, 210797.67],\n       [0.0, 1.0, 46014.02, 85047.44, 205517.64],\n       [1.0, 0.0, 28663.76, 127056.21, 201126.82],\n       [0.0, 0.0, 44069.95, 51283.14, 197029.42],\n       [0.0, 1.0, 20229.59, 65947.93, 185265.1],\n       [0.0, 0.0, 38558.51, 82982.09, 174999.3],\n       [0.0, 0.0, 28754.33, 118546.05, 172795.67],\n       [1.0, 0.0, 27892.92, 84710.77, 164470.71],\n       [0.0, 0.0, 23640.93, 96189.63, 148001.11],\n       [0.0, 1.0, 15505.73, 127382.3, 35534.17],\n       [0.0, 0.0, 22177.74, 154806.14, 28334.72],\n       [0.0, 1.0, 1000.23, 124153.04, 1903.93],\n       [1.0, 0.0, 1315.46, 115816.21, 297114.46],\n       [0.0, 0.0, 0.0, 135426.92, 0.0],\n       [0.0, 1.0, 542.05, 51743.15, 0.0],\n       [0.0, 0.0, 0.0, 116983.8, 45173.06]], dtype=object)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.concatenate([X_onehot, X[:, :-1]], axis=1)\n",
    "X_new"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "拆分训练和测试数据"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.0, 0.0, 55493.95, 103057.49, 214634.81],\n       [0.0, 1.0, 46014.02, 85047.44, 205517.64],\n       [1.0, 0.0, 75328.87, 144135.98, 134050.07],\n       [0.0, 0.0, 46426.07, 157693.92, 210797.67],\n       [1.0, 0.0, 91749.16, 114175.79, 294919.57],\n       [1.0, 0.0, 130298.13, 145530.06, 323876.68],\n       [1.0, 0.0, 119943.24, 156547.42, 256512.92],\n       [0.0, 1.0, 1000.23, 124153.04, 1903.93],\n       [0.0, 1.0, 542.05, 51743.15, 0.0],\n       [0.0, 1.0, 65605.48, 153032.06, 107138.38],\n       [0.0, 1.0, 114523.61, 122616.84, 261776.23],\n       [1.0, 0.0, 61994.48, 115641.28, 91131.24],\n       [0.0, 0.0, 63408.86, 129219.61, 46085.25],\n       [0.0, 0.0, 78013.11, 121597.55, 264346.06],\n       [0.0, 0.0, 23640.93, 96189.63, 148001.11],\n       [0.0, 0.0, 76253.86, 113867.3, 298664.47],\n       [0.0, 1.0, 15505.73, 127382.3, 35534.17],\n       [0.0, 1.0, 120542.52, 148718.95, 311613.29],\n       [0.0, 0.0, 91992.39, 135495.07, 252664.93],\n       [0.0, 0.0, 64664.71, 139553.16, 137962.62],\n       [0.0, 1.0, 131876.9, 99814.71, 362861.36],\n       [0.0, 1.0, 94657.16, 145077.58, 282574.31],\n       [0.0, 0.0, 28754.33, 118546.05, 172795.67],\n       [0.0, 0.0, 0.0, 116983.8, 45173.06],\n       [0.0, 0.0, 162597.7, 151377.59, 443898.53],\n       [1.0, 0.0, 93863.75, 127320.38, 249839.44],\n       [0.0, 0.0, 44069.95, 51283.14, 197029.42],\n       [0.0, 1.0, 77044.01, 99281.34, 140574.81],\n       [0.0, 0.0, 134615.46, 147198.87, 127716.82],\n       [1.0, 0.0, 67532.53, 105751.03, 304768.73],\n       [1.0, 0.0, 28663.76, 127056.21, 201126.82],\n       [0.0, 1.0, 78389.47, 153773.43, 299737.29],\n       [0.0, 1.0, 86419.7, 153514.11, 0.0],\n       [0.0, 0.0, 123334.88, 108679.17, 304981.62],\n       [0.0, 0.0, 38558.51, 82982.09, 174999.3],\n       [1.0, 0.0, 1315.46, 115816.21, 297114.46],\n       [0.0, 1.0, 144372.41, 118671.85, 383199.62],\n       [0.0, 1.0, 165349.2, 136897.8, 471784.1],\n       [0.0, 0.0, 0.0, 135426.92, 0.0],\n       [0.0, 0.0, 22177.74, 154806.14, 28334.72]], dtype=object)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=0)\n",
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "拟合模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "LinearRegression()",
      "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "\n",
    "regressor.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "测试预测结果(all-in策略， 使用所有特征)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "构建优化模型，使用反向淘汰策略"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "添加截距"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1, 1.0, 0.0, 55493.95, 103057.49, 214634.81],\n       [1, 0.0, 1.0, 46014.02, 85047.44, 205517.64],\n       [1, 1.0, 0.0, 75328.87, 144135.98, 134050.07],\n       [1, 0.0, 0.0, 46426.07, 157693.92, 210797.67],\n       [1, 1.0, 0.0, 91749.16, 114175.79, 294919.57],\n       [1, 1.0, 0.0, 130298.13, 145530.06, 323876.68],\n       [1, 1.0, 0.0, 119943.24, 156547.42, 256512.92],\n       [1, 0.0, 1.0, 1000.23, 124153.04, 1903.93],\n       [1, 0.0, 1.0, 542.05, 51743.15, 0.0],\n       [1, 0.0, 1.0, 65605.48, 153032.06, 107138.38],\n       [1, 0.0, 1.0, 114523.61, 122616.84, 261776.23],\n       [1, 1.0, 0.0, 61994.48, 115641.28, 91131.24],\n       [1, 0.0, 0.0, 63408.86, 129219.61, 46085.25],\n       [1, 0.0, 0.0, 78013.11, 121597.55, 264346.06],\n       [1, 0.0, 0.0, 23640.93, 96189.63, 148001.11],\n       [1, 0.0, 0.0, 76253.86, 113867.3, 298664.47],\n       [1, 0.0, 1.0, 15505.73, 127382.3, 35534.17],\n       [1, 0.0, 1.0, 120542.52, 148718.95, 311613.29],\n       [1, 0.0, 0.0, 91992.39, 135495.07, 252664.93],\n       [1, 0.0, 0.0, 64664.71, 139553.16, 137962.62],\n       [1, 0.0, 1.0, 131876.9, 99814.71, 362861.36],\n       [1, 0.0, 1.0, 94657.16, 145077.58, 282574.31],\n       [1, 0.0, 0.0, 28754.33, 118546.05, 172795.67],\n       [1, 0.0, 0.0, 0.0, 116983.8, 45173.06],\n       [1, 0.0, 0.0, 162597.7, 151377.59, 443898.53],\n       [1, 1.0, 0.0, 93863.75, 127320.38, 249839.44],\n       [1, 0.0, 0.0, 44069.95, 51283.14, 197029.42],\n       [1, 0.0, 1.0, 77044.01, 99281.34, 140574.81],\n       [1, 0.0, 0.0, 134615.46, 147198.87, 127716.82],\n       [1, 1.0, 0.0, 67532.53, 105751.03, 304768.73],\n       [1, 1.0, 0.0, 28663.76, 127056.21, 201126.82],\n       [1, 0.0, 1.0, 78389.47, 153773.43, 299737.29],\n       [1, 0.0, 1.0, 86419.7, 153514.11, 0.0],\n       [1, 0.0, 0.0, 123334.88, 108679.17, 304981.62],\n       [1, 0.0, 0.0, 38558.51, 82982.09, 174999.3],\n       [1, 1.0, 0.0, 1315.46, 115816.21, 297114.46],\n       [1, 0.0, 1.0, 144372.41, 118671.85, 383199.62],\n       [1, 0.0, 1.0, 165349.2, 136897.8, 471784.1],\n       [1, 0.0, 0.0, 0.0, 135426.92, 0.0],\n       [1, 0.0, 0.0, 22177.74, 154806.14, 28334.72]], dtype=object)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.append(arr=np.ones((40, 1)).astype(int), values=X_train, axis=1)\n",
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用所有特征来拟合模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 5.5493950e+04,\n        1.0305749e+05, 2.1463481e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 4.6014020e+04,\n        8.5047440e+04, 2.0551764e+05],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 7.5328870e+04,\n        1.4413598e+05, 1.3405007e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.6426070e+04,\n        1.5769392e+05, 2.1079767e+05],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 9.1749160e+04,\n        1.1417579e+05, 2.9491957e+05],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.3029813e+05,\n        1.4553006e+05, 3.2387668e+05],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.1994324e+05,\n        1.5654742e+05, 2.5651292e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.0002300e+03,\n        1.2415304e+05, 1.9039300e+03],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 5.4205000e+02,\n        5.1743150e+04, 0.0000000e+00],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.5605480e+04,\n        1.5303206e+05, 1.0713838e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.1452361e+05,\n        1.2261684e+05, 2.6177623e+05],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.1994480e+04,\n        1.1564128e+05, 9.1131240e+04],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.3408860e+04,\n        1.2921961e+05, 4.6085250e+04],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.8013110e+04,\n        1.2159755e+05, 2.6434606e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.3640930e+04,\n        9.6189630e+04, 1.4800111e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.6253860e+04,\n        1.1386730e+05, 2.9866447e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.5505730e+04,\n        1.2738230e+05, 3.5534170e+04],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.2054252e+05,\n        1.4871895e+05, 3.1161329e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 9.1992390e+04,\n        1.3549507e+05, 2.5266493e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.4664710e+04,\n        1.3955316e+05, 1.3796262e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.3187690e+05,\n        9.9814710e+04, 3.6286136e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 9.4657160e+04,\n        1.4507758e+05, 2.8257431e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.8754330e+04,\n        1.1854605e+05, 1.7279567e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        1.1698380e+05, 4.5173060e+04],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.6259770e+05,\n        1.5137759e+05, 4.4389853e+05],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 9.3863750e+04,\n        1.2732038e+05, 2.4983944e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.4069950e+04,\n        5.1283140e+04, 1.9702942e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.7044010e+04,\n        9.9281340e+04, 1.4057481e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.3461546e+05,\n        1.4719887e+05, 1.2771682e+05],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.7532530e+04,\n        1.0575103e+05, 3.0476873e+05],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 2.8663760e+04,\n        1.2705621e+05, 2.0112682e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.8389470e+04,\n        1.5377343e+05, 2.9973729e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 8.6419700e+04,\n        1.5351411e+05, 0.0000000e+00],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.2333488e+05,\n        1.0867917e+05, 3.0498162e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 3.8558510e+04,\n        8.2982090e+04, 1.7499930e+05],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.3154600e+03,\n        1.1581621e+05, 2.9711446e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.4437241e+05,\n        1.1867185e+05, 3.8319962e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.6534920e+05,\n        1.3689780e+05, 4.7178410e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        1.3542692e+05, 0.0000000e+00],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.2177740e+04,\n        1.5480614e+05, 2.8334720e+04]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X_train[:, [0, 1, 2, 3, 4, 5]]\n",
    "X_opt = np.array(X_opt, dtype=float)\n",
    "X_opt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "拟合模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "regressor_OLS = sm.OLS(endog=y_train, exog=X_opt).fit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.950\n",
      "Model:                            OLS   Adj. R-squared:                  0.943\n",
      "Method:                 Least Squares   F-statistic:                     129.7\n",
      "Date:                Wed, 26 Jul 2023   Prob (F-statistic):           3.91e-21\n",
      "Time:                        11:43:26   Log-Likelihood:                -421.10\n",
      "No. Observations:                  40   AIC:                             854.2\n",
      "Df Residuals:                      34   BIC:                             864.3\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       4.255e+04   8358.538      5.091      0.000    2.56e+04    5.95e+04\n",
      "x1          -959.2842   4038.108     -0.238      0.814   -9165.706    7247.138\n",
      "x2           699.3691   3661.563      0.191      0.850   -6741.822    8140.560\n",
      "x3             0.7735      0.055     14.025      0.000       0.661       0.886\n",
      "x4             0.0329      0.066      0.495      0.624      -0.102       0.168\n",
      "x5             0.0366      0.019      1.884      0.068      -0.003       0.076\n",
      "==============================================================================\n",
      "Omnibus:                       15.823   Durbin-Watson:                   2.468\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               23.231\n",
      "Skew:                          -1.094   Prob(JB):                     9.03e-06\n",
      "Kurtosis:                       6.025   Cond. No.                     1.49e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.49e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(regressor_OLS.summary())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "删除第二列，因为 P 值最大 表示是否在加州，这个特征对模型的预测能力没有贡献"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "X_opt = X_train[:, [0, 1, 3, 4, 5]]\n",
    "X_opt = np.array(X_opt, dtype=float)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "regressor_OLS = sm.OLS(endog=y_train, exog=X_opt).fit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.950\n",
      "Model:                            OLS   Adj. R-squared:                  0.944\n",
      "Method:                 Least Squares   F-statistic:                     166.7\n",
      "Date:                Wed, 26 Jul 2023   Prob (F-statistic):           2.87e-22\n",
      "Time:                        11:43:26   Log-Likelihood:                -421.12\n",
      "No. Observations:                  40   AIC:                             852.2\n",
      "Df Residuals:                      35   BIC:                             860.7\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       4.292e+04   8020.397      5.352      0.000    2.66e+04    5.92e+04\n",
      "x1         -1272.1608   3639.780     -0.350      0.729   -8661.308    6116.986\n",
      "x2             0.7754      0.053     14.498      0.000       0.667       0.884\n",
      "x3             0.0319      0.065      0.488      0.629      -0.101       0.165\n",
      "x4             0.0363      0.019      1.902      0.065      -0.002       0.075\n",
      "==============================================================================\n",
      "Omnibus:                       16.074   Durbin-Watson:                   2.467\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               24.553\n",
      "Skew:                          -1.086   Prob(JB):                     4.66e-06\n",
      "Kurtosis:                       6.164   Cond. No.                     1.43e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.43e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(regressor_OLS.summary())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "删除第一列，因为 P 值最大 表示是否在纽约，这个特征对模型的预测能力没有贡献"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.0000000e+00, 5.5493950e+04, 1.0305749e+05, 2.1463481e+05],\n       [1.0000000e+00, 4.6014020e+04, 8.5047440e+04, 2.0551764e+05],\n       [1.0000000e+00, 7.5328870e+04, 1.4413598e+05, 1.3405007e+05],\n       [1.0000000e+00, 4.6426070e+04, 1.5769392e+05, 2.1079767e+05],\n       [1.0000000e+00, 9.1749160e+04, 1.1417579e+05, 2.9491957e+05],\n       [1.0000000e+00, 1.3029813e+05, 1.4553006e+05, 3.2387668e+05],\n       [1.0000000e+00, 1.1994324e+05, 1.5654742e+05, 2.5651292e+05],\n       [1.0000000e+00, 1.0002300e+03, 1.2415304e+05, 1.9039300e+03],\n       [1.0000000e+00, 5.4205000e+02, 5.1743150e+04, 0.0000000e+00],\n       [1.0000000e+00, 6.5605480e+04, 1.5303206e+05, 1.0713838e+05],\n       [1.0000000e+00, 1.1452361e+05, 1.2261684e+05, 2.6177623e+05],\n       [1.0000000e+00, 6.1994480e+04, 1.1564128e+05, 9.1131240e+04],\n       [1.0000000e+00, 6.3408860e+04, 1.2921961e+05, 4.6085250e+04],\n       [1.0000000e+00, 7.8013110e+04, 1.2159755e+05, 2.6434606e+05],\n       [1.0000000e+00, 2.3640930e+04, 9.6189630e+04, 1.4800111e+05],\n       [1.0000000e+00, 7.6253860e+04, 1.1386730e+05, 2.9866447e+05],\n       [1.0000000e+00, 1.5505730e+04, 1.2738230e+05, 3.5534170e+04],\n       [1.0000000e+00, 1.2054252e+05, 1.4871895e+05, 3.1161329e+05],\n       [1.0000000e+00, 9.1992390e+04, 1.3549507e+05, 2.5266493e+05],\n       [1.0000000e+00, 6.4664710e+04, 1.3955316e+05, 1.3796262e+05],\n       [1.0000000e+00, 1.3187690e+05, 9.9814710e+04, 3.6286136e+05],\n       [1.0000000e+00, 9.4657160e+04, 1.4507758e+05, 2.8257431e+05],\n       [1.0000000e+00, 2.8754330e+04, 1.1854605e+05, 1.7279567e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.1698380e+05, 4.5173060e+04],\n       [1.0000000e+00, 1.6259770e+05, 1.5137759e+05, 4.4389853e+05],\n       [1.0000000e+00, 9.3863750e+04, 1.2732038e+05, 2.4983944e+05],\n       [1.0000000e+00, 4.4069950e+04, 5.1283140e+04, 1.9702942e+05],\n       [1.0000000e+00, 7.7044010e+04, 9.9281340e+04, 1.4057481e+05],\n       [1.0000000e+00, 1.3461546e+05, 1.4719887e+05, 1.2771682e+05],\n       [1.0000000e+00, 6.7532530e+04, 1.0575103e+05, 3.0476873e+05],\n       [1.0000000e+00, 2.8663760e+04, 1.2705621e+05, 2.0112682e+05],\n       [1.0000000e+00, 7.8389470e+04, 1.5377343e+05, 2.9973729e+05],\n       [1.0000000e+00, 8.6419700e+04, 1.5351411e+05, 0.0000000e+00],\n       [1.0000000e+00, 1.2333488e+05, 1.0867917e+05, 3.0498162e+05],\n       [1.0000000e+00, 3.8558510e+04, 8.2982090e+04, 1.7499930e+05],\n       [1.0000000e+00, 1.3154600e+03, 1.1581621e+05, 2.9711446e+05],\n       [1.0000000e+00, 1.4437241e+05, 1.1867185e+05, 3.8319962e+05],\n       [1.0000000e+00, 1.6534920e+05, 1.3689780e+05, 4.7178410e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.3542692e+05, 0.0000000e+00],\n       [1.0000000e+00, 2.2177740e+04, 1.5480614e+05, 2.8334720e+04]])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X_train[:, [0, 3, 4, 5]]\n",
    "X_opt = np.array(X_opt, dtype=float)\n",
    "X_opt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "regressor_OLS = sm.OLS(endog=y_train, exog=X_opt).fit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.950\n",
      "Model:                            OLS   Adj. R-squared:                  0.946\n",
      "Method:                 Least Squares   F-statistic:                     227.8\n",
      "Date:                Wed, 26 Jul 2023   Prob (F-statistic):           1.85e-23\n",
      "Time:                        11:43:26   Log-Likelihood:                -421.19\n",
      "No. Observations:                  40   AIC:                             850.4\n",
      "Df Residuals:                      36   BIC:                             857.1\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       4.299e+04   7919.773      5.428      0.000    2.69e+04    5.91e+04\n",
      "x1             0.7788      0.052     15.003      0.000       0.674       0.884\n",
      "x2             0.0294      0.064      0.458      0.650      -0.101       0.160\n",
      "x3             0.0347      0.018      1.896      0.066      -0.002       0.072\n",
      "==============================================================================\n",
      "Omnibus:                       15.557   Durbin-Watson:                   2.481\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               22.539\n",
      "Skew:                          -1.081   Prob(JB):                     1.28e-05\n",
      "Kurtosis:                       5.974   Cond. No.                     1.43e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.43e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(regressor_OLS.summary())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "删除第四列，因为 P 值最大 表示是行政开销，这个特征对模型的预测能力没有贡献"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.0000000e+00, 5.5493950e+04, 2.1463481e+05],\n       [1.0000000e+00, 4.6014020e+04, 2.0551764e+05],\n       [1.0000000e+00, 7.5328870e+04, 1.3405007e+05],\n       [1.0000000e+00, 4.6426070e+04, 2.1079767e+05],\n       [1.0000000e+00, 9.1749160e+04, 2.9491957e+05],\n       [1.0000000e+00, 1.3029813e+05, 3.2387668e+05],\n       [1.0000000e+00, 1.1994324e+05, 2.5651292e+05],\n       [1.0000000e+00, 1.0002300e+03, 1.9039300e+03],\n       [1.0000000e+00, 5.4205000e+02, 0.0000000e+00],\n       [1.0000000e+00, 6.5605480e+04, 1.0713838e+05],\n       [1.0000000e+00, 1.1452361e+05, 2.6177623e+05],\n       [1.0000000e+00, 6.1994480e+04, 9.1131240e+04],\n       [1.0000000e+00, 6.3408860e+04, 4.6085250e+04],\n       [1.0000000e+00, 7.8013110e+04, 2.6434606e+05],\n       [1.0000000e+00, 2.3640930e+04, 1.4800111e+05],\n       [1.0000000e+00, 7.6253860e+04, 2.9866447e+05],\n       [1.0000000e+00, 1.5505730e+04, 3.5534170e+04],\n       [1.0000000e+00, 1.2054252e+05, 3.1161329e+05],\n       [1.0000000e+00, 9.1992390e+04, 2.5266493e+05],\n       [1.0000000e+00, 6.4664710e+04, 1.3796262e+05],\n       [1.0000000e+00, 1.3187690e+05, 3.6286136e+05],\n       [1.0000000e+00, 9.4657160e+04, 2.8257431e+05],\n       [1.0000000e+00, 2.8754330e+04, 1.7279567e+05],\n       [1.0000000e+00, 0.0000000e+00, 4.5173060e+04],\n       [1.0000000e+00, 1.6259770e+05, 4.4389853e+05],\n       [1.0000000e+00, 9.3863750e+04, 2.4983944e+05],\n       [1.0000000e+00, 4.4069950e+04, 1.9702942e+05],\n       [1.0000000e+00, 7.7044010e+04, 1.4057481e+05],\n       [1.0000000e+00, 1.3461546e+05, 1.2771682e+05],\n       [1.0000000e+00, 6.7532530e+04, 3.0476873e+05],\n       [1.0000000e+00, 2.8663760e+04, 2.0112682e+05],\n       [1.0000000e+00, 7.8389470e+04, 2.9973729e+05],\n       [1.0000000e+00, 8.6419700e+04, 0.0000000e+00],\n       [1.0000000e+00, 1.2333488e+05, 3.0498162e+05],\n       [1.0000000e+00, 3.8558510e+04, 1.7499930e+05],\n       [1.0000000e+00, 1.3154600e+03, 2.9711446e+05],\n       [1.0000000e+00, 1.4437241e+05, 3.8319962e+05],\n       [1.0000000e+00, 1.6534920e+05, 4.7178410e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n       [1.0000000e+00, 2.2177740e+04, 2.8334720e+04]])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X_train[:, [0, 3, 5]]\n",
    "X_opt = np.array(X_opt, dtype=float)\n",
    "X_opt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "regressor_OLS = sm.OLS(endog=y_train, exog=X_opt).fit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.950\n",
      "Model:                            OLS   Adj. R-squared:                  0.947\n",
      "Method:                 Least Squares   F-statistic:                     349.0\n",
      "Date:                Wed, 26 Jul 2023   Prob (F-statistic):           9.65e-25\n",
      "Time:                        11:43:26   Log-Likelihood:                -421.30\n",
      "No. Observations:                  40   AIC:                             848.6\n",
      "Df Residuals:                      37   BIC:                             853.7\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       4.635e+04   2971.236     15.598      0.000    4.03e+04    5.24e+04\n",
      "x1             0.7886      0.047     16.846      0.000       0.694       0.883\n",
      "x2             0.0326      0.018      1.860      0.071      -0.003       0.068\n",
      "==============================================================================\n",
      "Omnibus:                       14.666   Durbin-Watson:                   2.518\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               20.582\n",
      "Skew:                          -1.030   Prob(JB):                     3.39e-05\n",
      "Kurtosis:                       5.847   Cond. No.                     4.97e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.97e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(regressor_OLS.summary())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "删除第三列，因为 P 值最大（0.071） 表示是市场开销，这个特征对模型的预测能力没有贡献"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "X_opt = X_train[:, [0, 5]]\n",
    "X_opt = np.array(X_opt, dtype=float)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "regressor_OLS = sm.OLS(endog=y_train, exog=X_opt).fit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.564\n",
      "Model:                            OLS   Adj. R-squared:                  0.552\n",
      "Method:                 Least Squares   F-statistic:                     49.08\n",
      "Date:                Wed, 26 Jul 2023   Prob (F-statistic):           2.42e-08\n",
      "Time:                        11:43:26   Log-Likelihood:                -464.50\n",
      "No. Observations:                  40   AIC:                             933.0\n",
      "Df Residuals:                      38   BIC:                             936.4\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       5.971e+04   8319.622      7.177      0.000    4.29e+04    7.65e+04\n",
      "x1             0.2461      0.035      7.005      0.000       0.175       0.317\n",
      "==============================================================================\n",
      "Omnibus:                        5.414   Durbin-Watson:                   1.991\n",
      "Prob(Omnibus):                  0.067   Jarque-Bera (JB):                5.616\n",
      "Skew:                          -0.318   Prob(JB):                       0.0603\n",
      "Kurtosis:                       4.722   Cond. No.                     4.54e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.54e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(regressor_OLS.summary())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "最终结论：只有 R&D 开销对模型的预测能力有贡献"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
